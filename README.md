# tube üö∞

![Le tube](tube.png)
(Image par [Dall-E 3](https://openai.com/dall-e-3))

Interface R d'acc√®s √† la plateforme de donn√©es _Ellipse_.

## Pr√©-requis

### Installation
Pour installer ce package, utilisez la commande `remotes::install_github("ellipse-science/tube")`  ou `devtools::install_github("ellipse-science/tube")`.  Si les packages d√©pendants ne sont pas √† jour, SVP assurez-vous de chois l'option 1 pour tous les mettre √† jour.

### Cl√© d'acc√®s
Pour acc√©der aux donn√©es de la plateforme, il faut configurer les cl√©s d'acc√®s AWS. Pour obtenir ces informations, contacter Patrick Poncet (@patoscope) sur Slack.

Ensuite, il faut les ajouter au fichier `~/.Renviron` qui est charg√© au d√©marrage de la session R. Ce fichier r√©side √† la racine de votre r√©pertoire d'utilisateur. S'il n'existe pas, il faut le cr√©er ou le modifier avec la commande `usethis::edit_r_environ()`. Selon votre plateforme, l'emplacement du fichier est :

* Windows : `C:\Users\<votre utilisateur>\.Renviron`
* macOS : `/Users/<votre utilisateur>/.Renviron`
* Linux : `/home/<votre utilisateur>/.Renviron`

### Environnements
Il existe deux environnements (deux copies non identiques) de la plateforme de donn√©es sur AWS.

* Une copie de d√©veloppement (DEV) dans laquelle on d√©veloppe les pipelines et o√π on con√ßoit la structure des donn√©es (tables, variables etc.).  Vous allez principalement vous connecter en DEV pour valider le travail des d√©veloppeurs et la structure de donn√©es que leurs pipelines ont g√©n√©r√©e, en faisant des tests les plus r√©els possible selon vos projets de recherche, sur des petits √©chantillons de donn√©es.  vous pourries aussi utiliser l'environnement de DEV pour valider des dictionnaires ou des dimensions.
* Une copie de PROD: Lorsqu'on est satisfait avec la conception, on passe en production (PROD). L√† les donn√©es sont officielles, de qualit√© en tout temps, dans leur structure approuv√©e (par vous en DEV).

Un cas d'usage tr√®s fr√©quent sera de vous connecter en PROD pour obtenir les donn√©es r√©centes, √† jour, et en DEV pour publier des dataframes issus de vos travaux d'analyse dans R et valider leur qualit√© avant de les publier en PROD.  Nous avons plus de d√©tails sur √ßa plus loin.

Pour plus de d√©tails sur les environnements, voir le [diagramme descriptif des environnements de la plateforme `Ellipse`](https://github.com/ellipse-science/tube-doc/blob/main/ellipse-dev-prod.drawio.png).

Pour se connecter √† l'un et/ou l'autre des environnements, il faut le choisir au moment de la connection.  Pour cela, il faut configurer 2 paires "ID de cl√©"+"Secret de cl√©" comme suit:

```R
# .Renviron
AWS_ACCESS_KEY_ID_DEV=<identifiant de cl√© en DEV>
AWS_SECRET_ACCESS_KEY_DEV=<cl√© d''acc√®s secr√®te en DEV>
AWS_ACCESS_KEY_ID_PROD=<identifiant de cl√© en PROD>
AWS_SECRET_ACCESS_KEY_PROD=<cl√© d''acc√®s secr√®te en PROD>
```

Pour √©diter le fichier .Renviron tel qu'illustr√© ci-dessus, simplement lancer la commande `usethis::edit_r_environ()` dans votre console R.  Modifiez le fichier, enregistrez-le et red√©marrez votre session R

C'est au moment de la connexion √† la plateforme dans votre code R que vous devez choisir √† quel environnement vous voulez vous connecter, comme suit:

```R
tube::ellipse_connect(env = "DEV", database = "datawarehouse")
```

Additionnellement, comme le montre la commande ci-dessus, il vous faut sp√©cifier si votre connexion doit se faire sur l'entrep√¥t de donn√©es (datawarehouse) ou sur les comptoirs de donn√©es (datamarts).  Pour plus d'explications sur ces concepts, veuillez vous r√©f√©rer au repo [`tube-doc`](https://github.com/ellipse-science/tube-doc/tree/main) dans lequel on d√©crit [les trois composantes principales d'une platformes de donn√©es](https://github.com/ellipse-science/tube-doc/blob/main/ellipse-datalake-datawarehouse-datamart.drawio.png).

## Interface de haut hiveau

`tube` comporte une interface de haut niveau qui permet d'interroger la plateforme √† l'aide de fonctions d'analyse de donn√©es fournies par le `tidyverse`.

Pour faciliter la d√©couverte des fonctionnalit√©s, les noms de fonction commencent par `ellipse_`. Lorsque `tube` est charg√© dans RStudio avec `library(tube)`, taper les lettres `ell` dans la console R ou l'√©diteur permet de voir rapidement les fonctions disponibles.

Pour rappel, dans une session R, on peut taper `?<fonction>` pour obtenir de l'aide.

Des efforts sont d√©ploy√©s pour documenter les diff√©rentes fonctions fournies par `tube`. Si la documentation n'est pas ad√©quate, svp [ouvrir une _issue_](https://github.com/ellipse-science/tube/issues) sur ce d√©p√¥t pour nous permettre d'am√©liorer le package pour tout le monde üôÇ

### Se connecter

Pour se connecter, utiliser la fonction `ellipse_connect()`. Le seul param√®tre obligatoire est l'environnement (`DEV` ou `PROD`) :

```R
r$> con <- ellipse_connect(env = "PROD", database = "datawarehouse")
‚Ñπ Environnement: PROD
‚Ñπ Database: datawarehouse
‚Ñπ Pour d√©connecter: tube::ellipse_disconnect(objet_de_connexion)
‚Ñπ Base de donn√©es: gluestackdatawarehousedbe64d5725
‚úî Connexion √©tablie avec succ√®s! üëç
```

### D√©couvrir les donn√©es

La premi√®re √©tape de toute analyse est de rencenser les donn√©es √† notre disposition. C'est le r√¥le de la fonction `ellipse_discover()`. Elle prend minimalement en param√®tre l'objet de connexion obtenu √† l'√©tape pr√©c√©dente :

```r
[ins] r$> con <- ellipse_connect(env = "DEV", database = "datawarehouse")
‚Ñπ Environnement: DEV
‚Ñπ Database: datawarehouse
‚Ñπ Pour d√©connecter: DBI::dbDisconnect(objet_de_connexion)

[ins] r$> ellipse_discover(con)
# A tibble: 20 √ó 2
   categorie    table
   <chr>        <chr>
 1 Agora+       a-ca-parliament-debates
 2 Agora+       a-ca-press-releases
 3 Agora+       a-eu-parliament-debates
 4 Agora+       a-humans
 5 Agora+       a-qc-parliament-debates
 6 Agora+       a-qc-press-releases
 7 Dictionnaire dict-issues
 8 Dictionnaire dict-political-parties-can
 9 Dictionnaire dict-political-parties-qc
10 Dictionnaire dict-sentiments
11 Dimension    dim-institutions
12 Dimension    dim-medias
13 Dimension    dim-parliament-members
14 Dimension    dim-parties
15 Radar+       r-factiva
16 Radar+       r-media-frontpages
17 Radar+       r-media-headlines
18 Autre        test-datamart-csv_unprocessed
19 Autre        test2-datamart_partition1_unprocessed
20 Autre        test2-datamart_partition2_unprocessed
```

Un `tibble` est retourn√©. On peut y voir les tables qui sont disponibles. En ce moment, les tables retourn√©es sont celles contenues dans l'entrep√¥t de donn√©es (_data warehouse_).

Pour en savoir plus sur une table, on peut simplement la fournir en param√®tre comme suit :

```r
[ins] r$> ellipse_discover(con, "a-qc-parliament-debates")
INFO [2024-06-11 21:15:34] [tube::list_glue_tables] listing tables from the datawarehouse
# A tibble: 21 √ó 4
   table_name              col_name                 col_type is_partition
   <chr>                   <chr>                    <chr>    <lgl>
 1 a-qc-parliament-debates event_date               date     TRUE
 2 a-qc-parliament-debates id                       string   FALSE
 3 a-qc-parliament-debates institution_id           string   FALSE
 4 a-qc-parliament-debates event_number             string   FALSE
 5 a-qc-parliament-debates event_title              string   FALSE
 6 a-qc-parliament-debates event_start_time         string   FALSE
 7 a-qc-parliament-debates event_end_time           string   FALSE
 8 a-qc-parliament-debates timestamp                string   FALSE
 9 a-qc-parliament-debates order_of_business_number string   FALSE
10 a-qc-parliament-debates order_of_business_title  string   FALSE
# ‚Ñπ 11 more rows
# ‚Ñπ Use `print(n = ...)` to see more rows
```

Le concept de _partition_ est important. Le scan d'une table compl√®te peut √™tre tr√®s long et croissant selon la grosseur de la table. L'utilisation de partitions permet d'orienter la lecture des donn√©es en arri√®re plan pour lire directement les donn√©es souhait√©es et ainsi, am√©liore grandement les performances d'utilisation des donn√©es et r√©duit les co√ªts d'exploitation (**AWS facture proportionnellement √† la quantit√© de donn√©es lues**).

Les jeux de donn√©es de la plateforme _Ellipse_ sont partitionn√©s sur _AWS_, c'est-√†-dire que les donn√©es d'une table sont regroup√©es selon les valeurs de certaines variables. Regrouper les donn√©es de cette fa√ßon permet une efficacit√© accrue lorsqu'on fait une requ√™te pour utiliser les donn√©es. Ainsi, il est recommand√© d'utiliser ces variables lorsqu'on veut cibler un sous-ensemble de donn√©es. Pour ce faire, il faut conna√Ætre les valeurs que peuvent prendre ces variables partitionn√©es.

Dans l'exemple ci-haut, on voit que `event_date` est une variable partitionn√©e. Pour conna√Ætre les valeurs que peuvent prendre ces variables, on peut utiliser la fonction `ellipse_partitions()` :

```r
[ins] r$> parts <- ellipse_partitions(con, "a-qc-parliament-debates")
INFO [2024-06-11 21:18:12] [tube::list_glue_tables] listing tables from the datawarehouse
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 0 Bytes)

[ins] r$> print(parts)
# A tibble: 10 √ó 2
   event_date       n
   <date>     <int64>
 1 2024-05-21     262
 2 2024-05-22     309
 3 2024-05-23     262
 4 2024-05-28     263
 5 2024-05-29     320
 6 2024-05-30     259
 7 2024-05-31     223
 8 2024-06-04     305
 9 2024-06-05     293
10 2024-06-06     315
```

Un `tibble` est retourn√©. Chacune des lignes repr√©sente une combinaison de valeurs des variables partitionn√©es de la table, ainsi que le nombre d'observations associ√©es.

Ces valeurs peuvent nous guider dans nos requ√™tes subs√©quentes. √Ä l'usage, pour obtenir une partie des donn√©es, on remarquera que l'utilisation d'un filtre sur des variables partionn√©es sera beaucoup plus rapide que sur des variables non-partitionn√©es. Il est donc recommand√© d'utiliser les filtres de variables partitionn√©es en premier puis ceux sur les variables non-partionn√©es pour raffiner.

Comme il s'agit d'un `tibble` ordinaire, on peut l'explorer avec les fonctions habituelles de `dplyr`:

```r
[ins] r$> dplyr::filter(parts, n > 300)
# A tibble: 4 √ó 2
  event_date       n
  <date>     <int64>
1 2024-05-22     309
2 2024-05-29     320
3 2024-06-04     305
4 2024-06-06     315
```

### Interroger les donn√©es

#### Pipeline des d√©bats parlementaires

Maintenant qu'on a une id√©e des donn√©es qui nous int√©ressent et de la fa√ßon dont elles sont partitionn√©es, on peut les interroger.

La fonction `ellipse_query()` nous retourne un objet qui est exploitable avec `dplyr`.

N'est-il pas int√©ressant d'√©tudier les interventions du premier ministre √† l'assembl√©e nationale?

```r
[nav] df <-
        tube::ellipse_query(con, "a-qc-parliament-debates") |>
        dplyr::filter(event_date == "2024-05-23") |>
        dplyr::collect()
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 100.45 KB)

[ins] r$> df |>
            dplyr::filter(stringr::str_detect(speaker, "Legault")) |>
            dplyr::distinct(intervention_number, speaker, intervention_text)
# A tibble: 17 √ó 3
   intervention_number speaker          intervention_text                                                                                                 
   <chr>               <chr>            <chr>                                                                                                             
 1 380411-36           Fran√ßois Legault "Oui, Mme la Pr√©sidente. Bon, d'abord, c'est une de mes grandes fiert√©s, avec le ministre de l'√âconomie, d'avoir ‚Ä¶
 2 380411-40           Fran√ßois Legault "Mme la Pr√©sidente, d'abord, je veux rassurer tout le monde, le ministre de l'√âconomie, il n'est pas sortant, l√†,‚Ä¶
 3 380411-42           M. Legault       "...les salaires les plus √©lev√©s."                                                                                
 4 380411-51           Fran√ßois Legault "Oui, Mme la Pr√©sidente, le chef de l'opposition officielle n'a pas √©t√© gentil avec moi en fin de semaine. L√†, il‚Ä¶
 5 380411-56           Fran√ßois Legault "Mme la Pr√©sidente, quand le gouvernement lib√©ral √©tait au pouvoir, il y avait des tarifs privil√©gi√©s pour les en‚Ä¶
 6 380411-90           Fran√ßois Legault "Oui, Mme la Pr√©sidente, le Parti lib√©ral est un parti tr√®s courageux. Quand il rencontre les gens de Rivi√®re-du-‚Ä¶
 7 380411-99           M. Legault       "Donc, aujourd'hui, le Parti lib√©ral, √©tant donn√© qu'il y a des gens de Rivi√®re-du-Loup, bien, propose que la tra‚Ä¶
 8 380411-121          Fran√ßois Legault "Mme la Pr√©sidente, d'abord, c'est important de le r√©p√©ter, puis, avec raison, la vice-premi√®re ministre le r√©p√®t‚Ä¶
 9 380411-125          Fran√ßois Legault "Oui. Mme la Pr√©sidente, je sais que √ßa n'int√©resse pas beaucoup Qu√©bec solidaire, l'√©conomie, mais, quand on reg‚Ä¶
10 380411-129          Fran√ßois Legault "Oui. Je note deux choses, Mme la Pr√©sidente. D'abord, Qu√©bec solidaire pr√©f√©rerait qu'on √©lectrifie les boeufs a‚Ä¶
11 380411-151          Fran√ßois Legault "Oui, Mme la Pr√©sidente, c'est vrai depuis tous les rapports qui ont √©t√© d√©pos√©s, entre autres le rapport de Mich‚Ä¶
12 380411-155          Fran√ßois Legault "Oui, Mme la Pr√©sidente, ce qui est important, puis l'objectif, c'est qu'il y ait plus de Qu√©b√©cois qui soient pr‚Ä¶
13 380411-157          M. Legault       "...par une infirmi√®re. C'est ce qu'on fait."                                                                     
14 380411-161          Fran√ßois Legault "Oui, Mme la Pr√©sidente. Bien, d'abord, on a d√©j√† revu le mode de r√©mun√©ration, c'√©tait dans une entente qui se t‚Ä¶
15 380411-208          M. Legault       "M. le Pr√©sident, je propose, apr√®s consultation aupr√®s des partis d'opposition et des d√©put√©s ind√©pendants :\n¬´Q‚Ä¶
16 380411-213          M. Legault       "Oui. M. le Pr√©sident, je propose, apr√®s consultation aupr√®s des partis de l'opposition et des d√©put√©s ind√©pendan‚Ä¶
17 380411-36           Fran√ßois Legault "Oui, Mme la Pr√©sidente. Bon, d'abord, c'est une de mes grandes fiert√©s, avec le ministre de l'√âconomie, d'avoir ‚Ä¶
```

#### Pipeline des unes des m√©dias

On peut, par exemple, rechercher les titres des unes d'un m√©dia pour une journ√©e particuli√®re.

```r
[ins] r$> ellipse_discover(con, "r-media-headlines")
INFO [2024-03-30 10:21:04] [tube::list_glue_tables] listing tables from the datawarehouse
# A tibble: 13 √ó 4
   table_name        col_name               col_type is_partition
   <chr>             <chr>                  <chr>    <lgl>       
 1 r-media-headlines extraction_year        int      TRUE        
 2 r-media-headlines extraction_month       int      TRUE        
 3 r-media-headlines extraction_day         int      TRUE        
 4 r-media-headlines media_id               string   TRUE        
 5 r-media-headlines id                     string   FALSE       
 6 r-media-headlines extraction_date        date     FALSE       
 7 r-media-headlines extraction_time        string   FALSE       
 8 r-media-headlines publish_date           date     FALSE       
 9 r-media-headlines title                  string   FALSE       
10 r-media-headlines author                 string   FALSE       
11 r-media-headlines body                   string   FALSE       
12 r-media-headlines metadata_url           string   FALSE       
13 r-media-headlines metadata_lake_item_key string   FALSE  

[ins] r$> ellipse_partitions(con, "r-media-headlines")
INFO [2024-03-30 10:21:51] [tube::list_glue_tables] listing tables from the datawarehouse
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 0 Bytes)
# A tibble: 715 √ó 5
   extraction_year extraction_month extraction_day media_id       n
             <int>            <int>          <int> <chr>    <int64>
 1            2024                5             28 CBC           27
 2            2024                5             28 CTV           27
 3            2024                5             28 GAM           27
 4            2024                5             28 GN            27
 5            2024                5             28 JDM           30
 6            2024                5             28 LAP           27
 7            2024                5             28 LED           27
 8            2024                5             28 MG            27
 9            2024                5             28 NP            30
10            2024                5             28 RCI           30
# ‚Ñπ 705 more rows
# ‚Ñπ Use `print(n = ...)` to see more rows

[ins] r$> df <-
            ellipse_query(con, "r-media-headlines") |>
            dplyr::filter(extraction_year == 2024, extraction_month == 5, media_id == "RCI") |>
            dplyr::collect()
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 526.42 KB)

[ins] r$> df |>
            dplyr::mutate(
              date_heure = lubridate::as_datetime(paste(extraction_date, extraction_time),
              tz = "America/New_York")) |>
            dplyr::distinct(date_heure, title)
Date in ISO8601 format; converting timezone from UTC to "America/New_York".
# A tibble: 143 √ó 2
   date_heure          title
   <dttm>              <chr>
 1 2024-01-31 02:34:33 Demandeurs d‚Äôasile : Ottawa ne r√©pondra pas √† toutes les demandes du Qu√©bec | Radio-Canada
 2 2024-01-30 18:04:33 Scandale de Hockey Canada :  McLeod et Dub√© parmi les cinq joueurs accus√©s | Radio-Canada
 3 2024-01-30 23:54:33 Demandeurs d‚Äôasile : Ottawa ne r√©pondra pas √† toutes les demandes du Qu√©bec | Radio-Canada
 4 2024-01-31 03:24:34 Demandeurs d‚Äôasile : Ottawa ne r√©pondra pas √† toutes les demandes du Qu√©bec | Radio-Canada
 5 2024-01-30 16:44:34 Le nucl√©aire devrait faire partie de la solution apr√®s 2035, dit Hydro-Qu√©bec | Radio-Canada
 6 2024-01-30 15:04:33 Qu√©bec annonce 200 millions $ en allocations personnalis√©es aux RPA | Radio-Canada
 7 2024-01-30 17:54:33 Scandale de Hockey Canada :  McLeod et Dub√© parmi les cinq joueurs accus√©s | Radio-Canada
 8 2024-01-31 00:54:33 Demandeurs d‚Äôasile : Ottawa ne r√©pondra pas √† toutes les demandes du Qu√©bec | Radio-Canada
 9 2024-01-30 19:04:33 Scandale de Hockey Canada : l‚Äôidentit√© de 4 des 5 joueurs accus√©s est confirm√©e | Radio-Canada
10 2024-01-30 23:34:33 Demandeurs d‚Äôasile : Ottawa ne r√©pondra pas √† toutes les demandes du Qu√©bec | Radio-Canada
# ‚Ñπ 133 more rows
# ‚Ñπ Use `print(n = ...)` to see more rows
```

### Croiser des donn√©es

1. Aller chercher les m√©dias dans l'entrep√¥t de donn√©es en DEV

Les m√©dias, comme les autres donn√©es de r√©f√©rences du CAPP, sont ce qu'on appelle des donn√©es dimensionnelles.  Pour plus d'information sur les donn√©es dimensionnelles, veuillez consulter le [README du d√©p√¥t tube-dimensions](https://github.com/ellipse-science/tube-dimensions/blob/main/README.md), le [diagramme de flux de travail organique des dimensions](https://github.com/ellipse-science/tube-doc/blob/main/dimensions-workflow-organique.drawio.png) ainsi que le [diagramme de flux de travail organisationnel des dimensions](https://github.com/ellipse-science/tube-doc/blob/main/dimensions-workflow-organisationnel.drawio.png).

```r
[ins] r$> condwd <- tube::ellipse_connect("DEV", "datawarehouse")
‚Ñπ Environnement: DEV
‚Ñπ Database: datawarehouse
‚Ñπ Pour d√©connecter: tube::ellipse_disconnect(objet_de_connexion)
‚Ñπ Base de donn√©es: gluestackdatawarehousedbe64d5725
‚úî Connexion √©tablie avec succ√®s! üëç

r$> df_medias <- tube::ellipse_query(condwd, "dim-medias") |>
      dplyr::collect()
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 4.98 KB)
```

1. Aller chercher les Unes des m√©dias dans l'entrep√¥t de donn√©es en PROD
```r
[ins] r$> condwp <- tube::ellipse_connect("PROD", "datawarehouse")
‚Ñπ Environnement: PROD
‚Ñπ Database: datawarehouse
‚Ñπ Pour d√©connecter: tube::ellipse_disconnect(objet_de_connexion)
‚Ñπ Base de donn√©es: gluestackdatawarehousedbe64d5725
‚úî Connexion √©tablie avec succ√®s! üëç

r$> df_headlines <- tube::ellipse_query(condwp, "r-media-headlines") |>
      dplyr::filter(extraction_year == 2024 & extraction_month == 7 & extraction_day == 22) |>
      dplyr::collect()
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 0 Bytes)
INFO: (Data scanned: 9.95 MB)
```

√Ä ce stade nous avons deux dataframe.  Pour les croiser l'un avec l'autre, il faut qu'ils aient deux colonnes qui contiennent les m√™mes valeurs standardis√©es.  Validons que c'est bien le cas.

```r
[ins] r$> colnames(df_medias)
 [1] "id"                     "long_name"              "short_name"             "other_names"            "lang"
 [6] "country_id"             "province_or_state"      "x_handle"               "web_site"               "start_date"
[11] "end_date"               "wikipedia_qid"          "wikipedia_url"          "metadata_lake_item_key" "metadata_url"
[16] "version"

r$> colnames(df_headlines)
 [1] "id"                     "extraction_date"        "extraction_time"        "publish_date"           "title"
 [6] "author"                 "body"                   "metadata_url"           "metadata_lake_item_key" "extraction_year"
[11] "extraction_month"       "extraction_day"         "media_id"
```

On va pouvoir joindre les deux datframes sur la colonne `id` de `df_medias` et `media_id` de `df_headlines`

```r
[ins] r$> df <- dplyr::inner_join(df_medias, df_headlines, by = c("id" = "media_id")) |>
      dplyr::select(id, province_or_state, title, body, extraction_date)

r$> head(df)
# A tibble: 6 √ó 5
  id    province_or_state title                                                                                        body  extraction_date
  <chr> <chr>             <chr>                                                                                        <chr> <date>
1 TVA   QC                EN DIRECT | Suivez les derniers d√©veloppements sur le retrait de Joe Biden √† la course √† la‚Ä¶ "Joe‚Ä¶ 2024-07-22
2 TVA   QC                EN DIRECT | Suivez les derniers d√©veloppements sur le retrait de Joe Biden √† la course √† la‚Ä¶ "Joe‚Ä¶ 2024-07-22
3 TVA   QC                EN DIRECT | Suivez les derniers d√©veloppements sur le retrait de Joe Biden √† la course √† la‚Ä¶ "Joe‚Ä¶ 2024-07-22
4 TVA   QC                EN DIRECT | Suivez les derniers d√©veloppements sur le retrait de Joe Biden √† la course √† la‚Ä¶ "Joe‚Ä¶ 2024-07-22
5 TVA   QC                EN DIRECT | Suivez les derniers d√©veloppements sur le retrait de Joe Biden √† la course √† la‚Ä¶ "Joe‚Ä¶ 2024-07-22
6 TVA   QC                EN DIRECT | Suivez les derniers d√©veloppements sur le retrait de Joe Biden √† la course √† la‚Ä¶ "Joe‚Ä¶ 2024-07-22
```

### Publier un jeu de donn√©es dans un datamart

Pour plus de d√©tails sur les concepts de datalake, datawarehouse, datamarts, voir [les trois composantes principales d'une platformes de donn√©es](https://github.com/ellipse-science/tube-doc/blob/main/ellipse-datalake-datawarehouse-datamart.drawio.png)


Pour publier notre nouveau jeu de donn√©es dans un datamart, on peut utiliser la fonction `tube::ellipse_publish()`.

```r
[ins] 

# Connexion au datamarts en DEV
r$> condmd <- tube::ellipse_connect("DEV", "datamarts")
‚Ñπ Environnement: DEV
‚Ñπ Database: datamarts
‚Ñπ Pour d√©connecter: tube::ellipse_disconnect(objet_de_connexion)
‚Ñπ Base de donn√©es: gluestackdatamartdbd046f685
‚úî Connexion √©tablie avec succ√®s! üëç

# publication de la table nomm√©e headlinesbyprovinces dans le datamart nomm√© myradardatamart
# avec le contenu du dataframe df, dans la base de donn√©es des datamarts en DEV
r$> tube::ellipse_publish(con = condmd,
      dataframe = df,
      datamart = "myradardatamart",
      table = "headlinesbyprovinces",
      tag = "headlines_du_22_juillet_2024")

‚úñ Le datamart fourni n'existe pas! üòÖ
‚ùìVoulez-vous cr√©er un nouveau datamart? (oui/non) oui
‚Ñπ Cr√©ation du datamart en cours...
‚úñ La table demand√©e n'existe pas

‚ùìVoulez-vous cr√©er la table? (oui/non) oui
‚Ñπ Cr√©ation de la table en cours...
‚úî La table a √©t√© cr√©√©e avec succ√®s.

‚ùìVoulez-vous traiter les donn√©es maintenant pour les rendre disponibles imm√©diatement?
  Si vous ne le faites pas maintenant, le traitement sers d√©clench√© automatiquement dans les 6 prochaines heures.
  Votre choix (oui/non) oui
‚úî Le traitement des donn√©es a √©t√© d√©clench√© avec succ√®s.
‚Ñπ Les donn√©es seront disponibles dans les prochaines minutes
‚Ñπ N'oubliez pas de vous d√©connecter de la plateforme ellipse avec `ellipse_disconnect(...)` üëã.
```

### Injecter des donn√©es brutes dans la plateforme Ellipse
La r√®gle c'est que l'injection de donn√©es dans Ellipse est automatis√©e de bout-en bout:  Les donn√©es sont extraites depuis les internets √† un intervalle d√©fini. Elles sont entrepos√©es dans le lac de donn√©es telles quelles.  Et ensuite elles sont transform√©es sous forme tabulaire et stock√©es dans l'entrep√¥t de donn√©es o√π vous pouvez y acc√©der avec les fonctions `ellipse_*`.  Il y a 3 exceptions √† cette r√®gle:

#### L'obtention des donn√©es brutes n'est pas automatisable
Dans certains cas, malheureusement, il n'est pas possible d'extraire les donn√©es brutes automatiquement.  Il faut qu'une personne se charge de collecter les fichiers contenant les donn√©es brutes et les pousse dans la plateforme de donn√©es Ellipse.  Pour cela il faut qu'un pipeline de donn√©es semi-automatis√© ait √©t√© d√©velopp√© pr√©alablement par un d√©veloppeur.  C'est le cas notamment des articles de presse disponibles dans la banque de donn√©es Factiva, de certains sondages (qualtrics) etc.  Pour comprendre le flus de travail reli√© √† ce type d'acquisition et traitement des donn√©es, veuilles vous r√©f√©rer √† [ce diagramme](https://github.com/ellipse-science/tube-doc/blob/main/pipeline_semi_automatise.drawio.png).  Pour toute question ou impr√©cision, n'h√©sitez pas √† ouvrir une issue dans ce d√©p√¥t.

#### Il s'agit de donn√©es dimensionnelles
Les donn√©es dimensionnelles sont les donn√©es de r√©f√©rences du CAPP.  Elles repr√©sentent les axes sur lesquelles nous sommes typiquement int√©ress√©s √† porter nos analyses.  Par exemple, le ton des d√©put√©s de l'Assembl√©e nationale du Qu√©bec **par parti** au fil du temps ou sur des **enjeux** pr√©cis.  Pour cela il nous fait croiser des donn√©es factuelles (les interventions des d√©put√©s) avec les donn√©es dimensionnelles (les d√©put√©s et leur attribut `party`) et un dictionnaire d'enjeux (voir prochaine section).

Lorsqu'on construire nos donn√©es de r√©f√©rences reviens √† construire les dimensions (des entit√©s comme partis, m√©dias, cisconscriptions etc).  Cela se fait en cr√©ant des CSV et en les injectant dans `Ellipse`.  Ensuite il faut les entretenir en fonction de l'√©volution des choses (p.ex. si un d√©put√© change de parti ou qu'il n'est pas r√©√©lu) et les r√©injecter dans la plateforme.

Cela se fait via des pipelines de donn√©es dimensionnelles.  Pour plus d'information veuillez lire le [README du d√©p√¥t tube-dimensions](https://github.com/ellipse-science/tube-dimensions) et vous r√©f√©rer √† aux diagrammes de flux de travail qui d√©crivent l'injection de donn√©es dimentionnelles dans `Ellipse`:  [ici](https://github.com/ellipse-science/tube-doc/blob/main/dimensions-workflow-organique.drawio.png) et [ici](https://github.com/ellipse-science/tube-doc/blob/main/dimensions-workflow-organisationnel.drawio.png).

#### Il s'agit de dictionnaires
Les dictionnaires sont des donn√©es dimensionnelles (dans le sens qu'elles sont des donn√©es de r√©f√©rences du CAPP).  Elles sont d√©di√©es √† l'analyse textuelles.  Nos dictionnaires sont construits de toute pi√®ce, manuellement, via des techniques particuli√®res.  Pour plus de d√©tails sur les dictionnaires, veuillez consultes le [README du d√©p√¥t tube-dictionaries]([https://github.com/ellipse-science/tube-dictionaries/tree/main](https://github.com/ellipse-science/tube-dictionaries/blob/develop/README.md).

### Notes sur dplyr

Les verbes `dplyr` disponibles sont limit√©s sur une source distante comme la plateforme _Ellipse_. Une fois qu'on a une id√©e des donn√©es que l'on veut, on peut envoyer une requ√™te qui filtre sur une plage de valeurs pertinentes pour les partitions pr√©sentes, puis utiliser la fonction `dplyr::collect()` pour ramener les donn√©es localement. Apr√®s ceci, toute la fonctionnalit√© de manipulation de donn√©es de R et du _tidyverse_ sont disponibles pour traiter les donn√©es.

## Development Setup

### For Package Contributors

This package follows strict development guidelines with comprehensive testing and quality assurance.

#### Required Environment Variables

The package requires AWS credentials in your `.Renviron` file:

```
AWS_ACCESS_KEY_ID_DEV=<your dev access key>
AWS_SECRET_ACCESS_KEY_DEV=<your dev secret key>
AWS_ACCESS_KEY_ID_PROD=<your prod access key>
AWS_SECRET_ACCESS_KEY_PROD=<your prod secret key>
AWS_REGION=ca-central-1
```

#### Development Workflow

1. **Clone and setup**:
   ```r
   # Install development dependencies
   remotes::install_dev_deps()
   install.packages(c("lintr", "covr", "testthat", "mockery"))
   ```

2. **Quality Assurance Scripts**:
   ```r
   # Load QA functions
   source("dev-qa-scripts.R")
   
   # Quick check during development
   quick_check()
   
   # Full QA pipeline before commits
   qa_pipeline()
   ```

3. **Pre-commit Hooks** (recommended):
   ```bash
   pip install pre-commit
   pre-commit install
   ```

#### Testing Requirements

- **100% test coverage required** - no exceptions
- All tests must pass before any commits
- Tests use mocked AWS services to avoid real API calls
- Environment variables are mocked for testing

#### Code Quality Standards

- **All code must pass `lintr::lint_package()`**
- Follow existing `.lintr` configuration
- Use roxygen2 documentation for all exported functions
- Follow consistent naming conventions (snake_case)

#### CI/CD Pipeline

GitHub Actions automatically runs:
- Linting checks (must pass)
- Full test suite (must pass) 
- Test coverage analysis (95%+ required)
- R CMD check (must pass)

#### Contributing

1. Create feature branch from `main`
2. Implement changes with full test coverage
3. Run `qa_pipeline()` locally
4. Submit pull request
5. All CI/CD checks must pass

For conceptual documentation, see [tube-doc](https://github.com/ellipse-science/tube-doc/tree/main)
